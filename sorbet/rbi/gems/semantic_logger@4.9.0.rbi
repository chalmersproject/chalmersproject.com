# typed: true

# DO NOT EDIT MANUALLY
# This is an autogenerated file for types exported from the `semantic_logger` gem.
# Please instead update this file by running `bin/tapioca gem semantic_logger`.

# @formatter:off
module SemanticLogger
  class << self
    # Return a logger for the supplied class or class_name
    def [](klass); end

    # Add a new logging appender as a new destination for all log messages
    # emitted from Semantic Logger
    #
    # Appenders will be written to in the order that they are added
    #
    # If a block is supplied then it will be used to customize the format
    # of the messages sent to that appender. See SemanticLogger::Logger.new for
    # more information on custom formatters
    #
    # Parameters
    # file_name: [String]
    # File name to write log messages to.
    #
    # Or,
    # io: [IO]
    # An IO Stream to log to.
    # For example $stdout, $stderr, etc.
    #
    # Or,
    # appender: [Symbol|SemanticLogger::Subscriber]
    # A symbol identifying the appender to create.
    # For example:
    # :bugsnag, :elasticsearch, :graylog, :http, :mongodb, :new_relic, :splunk_http, :syslog, :wrapper
    # Or,
    # An instance of an appender derived from SemanticLogger::Subscriber
    # For example:
    # SemanticLogger::Appender::Http.new(url: 'http://localhost:8088/path')
    #
    # Or,
    # logger: [Logger|Log4r]
    # An instance of a Logger or a Log4r logger.
    #
    # level: [:trace | :debug | :info | :warn | :error | :fatal]
    # Override the log level for this appender.
    # Default: SemanticLogger.default_level
    #
    # formatter: [Symbol|Object|Proc]
    # Any of the following symbol values: :default, :color, :json, :logfmt, etc...
    # Or,
    # An instance of a class that implements #call
    # Or,
    # A Proc to be used to format the output from this appender
    # Default: :default
    #
    # filter: [Regexp|Proc]
    # RegExp: Only include log messages where the class name matches the supplied.
    # regular expression. All other messages will be ignored.
    # Proc: Only include log messages where the supplied Proc returns true
    # The Proc must return true or false.
    #
    # Examples:
    #
    # # Send all logging output to Standard Out (Screen)
    # SemanticLogger.add_appender(io: $stdout)
    #
    # # Send all logging output to a file
    # SemanticLogger.add_appender(file_name: 'logfile.log')
    #
    # # Send all logging output to a file and only :info and above to standard output
    # SemanticLogger.add_appender(file_name: 'logfile.log')
    # SemanticLogger.add_appender(io: $stdout, level: :info)
    #
    # Log to log4r, Logger, etc.:
    #
    # # Send Semantic logging output to an existing logger
    # require 'logger'
    # require 'semantic_logger'
    #
    # # Built-in Ruby logger
    # log = Logger.new($stdout)
    # log.level = Logger::DEBUG
    #
    # SemanticLogger.default_level = :debug
    # SemanticLogger.add_appender(logger: log)
    #
    # logger = SemanticLogger['Example']
    # logger.info "Hello World"
    # logger.debug("Login time", user: 'Joe', duration: 100, ip_address: '127.0.0.1')
    def add_appender(**args, &block); end

    # Add signal handlers for Semantic Logger
    #
    # Two signal handlers will be registered by default:
    #
    # 1. Changing the log_level:
    #
    # The log level can be changed without restarting the process by sending the
    # log_level_signal, which by default is 'USR2'
    #
    # When the log_level_signal is raised on this process, the global default log level
    # rotates through the following log levels in the following order, starting
    # from the current global default level:
    # :warn, :info, :debug, :trace
    #
    # If the current level is :trace it wraps around back to :warn
    #
    # 2. Logging a Ruby thread dump
    #
    # When the signal is raised on this process, Semantic Logger will write the list
    # of threads to the log file, along with their back-traces when available
    #
    # For JRuby users this thread dump differs form the standard QUIT triggered
    # Java thread dump which includes system threads and Java stack traces.
    #
    # It is recommended to name any threads you create in the application, by
    # calling the following from within the thread itself:
    # Thread.current.name = 'My Worker'
    #
    # Also adds JRuby Garbage collection logging so that any garbage collections
    # that exceed the time threshold will be logged. Default: 100 ms
    # Currently only supported when running JRuby
    #
    # Note:
    # To only register one of the signal handlers, set the other to nil
    # Set gc_log_microseconds to nil to not enable JRuby Garbage collections
    def add_signal_handler(log_level_signal = T.unsafe(nil), thread_dump_signal = T.unsafe(nil), gc_log_microseconds = T.unsafe(nil)); end

    # Returns [SemanticLogger::Subscriber] a copy of the list of active
    # appenders for debugging etc.
    # Use SemanticLogger.add_appender and SemanticLogger.remove_appender
    # to manipulate the active appenders list
    def appenders; end

    # Returns [String] name of this application for logging purposes
    # Note: Not all appenders use `application`
    def application; end

    # Override the default application
    def application=(application); end

    # Returns the current backtrace level
    def backtrace_level; end

    # Sets the level at which backtraces should be captured
    # for every log message.
    #
    # By enabling backtrace capture the filename and line number of where
    # message was logged can be written to the log file. Additionally, the backtrace
    # can be forwarded to error management services such as Bugsnag.
    #
    # Warning:
    # Capturing backtraces is very expensive and should not be done all
    # the time. It is recommended to run it at :error level in production.
    def backtrace_level=(level); end

    # Returns the current backtrace level index
    # For internal use only
    def backtrace_level_index; end

    # Clear out all previously registered appenders
    def clear_appenders!; end

    # Close all appenders and flush any outstanding messages.
    def close; end

    # Returns the global default log level
    def default_level; end

    # Sets the global default log level
    def default_level=(level); end

    def default_level_index; end

    # Returns [String] name of this environment for logging purposes
    # Note: Not all appenders use `environment`
    def environment; end

    # Override the default environment
    def environment=(environment); end

    # If the tag being supplied is definitely a string then this fast
    # tag api can be used for short lived tags
    def fast_tag(tag); end

    # Flush all queued log entries disk, database, etc.
    # All queued log messages are written and then each appender is flushed in turn.
    def flush; end

    # Returns [String] name of this host for logging purposes
    # Note: Not all appenders use `host`
    def host; end

    # Override the default host name
    def host=(host); end

    # Returns the check_interval which is the number of messages between checks
    # to determine if the appender thread is falling behind.
    def lag_check_interval; end

    # Set the check_interval which is the number of messages between checks
    # to determine if the appender thread is falling behind.
    def lag_check_interval=(lag_check_interval); end

    # Returns the amount of time in seconds
    # to determine if the appender thread is falling behind.
    def lag_threshold_s; end

    # :nodoc
    def named_tagged(hash); end

    # Returns [Hash] a copy of the named tags currently active for this thread.
    def named_tags; end

    # Supply a callback to be called whenever a log entry is created.
    # Useful for capturing appender specific context information.
    #
    # Parameters
    # object: [Object | Proc]
    # [Proc] the block to call.
    # [Object] any object on which to call #call.
    #
    # Example:
    # SemanticLogger.on_log do |log|
    # log.set_context(:honeybadger, Honeybadger.get_context)
    # end
    #
    # Example:
    # module CaptureContext
    # def call(log)
    # log.set_context(:honeybadger, Honeybadger.get_context)
    # end
    # end
    # SemanticLogger.on_log(CaptureContext)
    #
    # Note:
    # * This callback is called within the thread of the application making the logging call.
    # * If these callbacks are slow they will slow down the application.
    def on_log(object = T.unsafe(nil), &block); end

    def pop_named_tags(quantity = T.unsafe(nil)); end

    # Remove specified number of tags from the current tag list
    def pop_tags(quantity = T.unsafe(nil)); end

    def push_named_tags(hash); end

    # Add tags to the current scope
    #
    # Note:
    # - This method does not flatten the array or remove any empty elements, or duplicates
    # since the performance penalty is excessive.
    # - To get the flattening behavior use the slower api:
    # `logger.push_tags`
    def push_tags(*tags); end

    # Returns [Integer] the number of log entries waiting to be written to the appenders.
    #
    # When this number grows it is because the logging appender thread is not
    # able to write to the appenders fast enough. Either reduce the amount of
    # logging, increase the log level, reduce the number of appenders, or
    # look into speeding up the appenders themselves
    def queue_size; end

    # Remove an existing appender
    # Currently only supports appender instances
    def remove_appender(appender); end

    # After forking an active process call SemanticLogger.reopen to re-open
    # any open file handles etc to resources.
    #
    # Note:
    # Not all appender's implement reopen.
    # Check the code for each appender you are using before relying on this behavior.
    def reopen; end

    # Silence noisy log levels by changing the default_level within the block
    #
    # This setting is thread-safe and only applies to the current thread
    #
    # Any threads spawned within the block will not be affected by this setting
    #
    # #silence can be used to both raise and lower the log level within
    # the supplied block.
    #
    # Example:
    #
    # # Perform trace level logging within the block when the default is higher
    # SemanticLogger.default_level = :info
    #
    # logger.debug 'this will _not_ be logged'
    #
    # SemanticLogger.silence(:trace) do
    # logger.debug "this will be logged"
    # end
    #
    # Parameters
    # new_level
    # The new log level to apply within the block
    # Default: :error
    #
    # Example:
    # # Silence all logging for this thread below :error level
    # SemanticLogger.silence do
    # logger.info "this will _not_ be logged"
    # logger.warn "this neither"
    # logger.error "but errors will be logged"
    # end
    #
    # Note:
    # #silence does not affect any loggers which have had their log level set
    # explicitly. I.e. That do not rely on the global default level
    def silence(new_level = T.unsafe(nil)); end

    # Run Semantic Logger in Synchronous mode.
    #
    # I.e. Instead of logging messages in a separate thread for better performance,
    # log them using the current thread.
    def sync!; end

    # Running in synchronous mode?
    def sync?; end

    # Add the tags or named tags to the list of tags to log for this thread whilst the supplied block is active.
    #
    # Returns result of block.
    #
    # Tagged example:
    # SemanticLogger.tagged(12345, 'jack') do
    # logger.debug('Hello World')
    # end
    #
    # Named Tags (Hash) example:
    # SemanticLogger.tagged(tracking_number: 12345) do
    # logger.debug('Hello World')
    # end
    #
    # Notes:
    # - Tags should be a list without any empty values, or contain any array.
    # - `logger.tagged` is a slower api that will flatten the example below:
    # `logger.tagged([['first', nil], nil, ['more'], 'other'])`
    # to the equivalent of:
    # `logger.tagged('first', 'more', 'other')`
    def tagged(*tags, &block); end

    # Returns a copy of the [Array] of [String] tags currently active for this thread
    # Returns nil if no tags are set
    def tags; end
  end
end

# Formatting & colors used by optional color formatter
module SemanticLogger::AnsiColors; end

SemanticLogger::AnsiColors::BLACK = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::BLUE = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::BOLD = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::CLEAR = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::CYAN = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::GREEN = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::MAGENTA = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::RED = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::WHITE = T.let(T.unsafe(nil), String)
SemanticLogger::AnsiColors::YELLOW = T.let(T.unsafe(nil), String)

module SemanticLogger::Appender
  class << self
    # Returns [SemanticLogger::Subscriber] appender for the supplied options
    def factory(async: T.unsafe(nil), batch: T.unsafe(nil), max_queue_size: T.unsafe(nil), lag_check_interval: T.unsafe(nil), lag_threshold_s: T.unsafe(nil), batch_size: T.unsafe(nil), batch_seconds: T.unsafe(nil), **args, &block); end

    private

    # Returns [Subscriber] instance from the supplied options.
    def build(io: T.unsafe(nil), file_name: T.unsafe(nil), appender: T.unsafe(nil), metric: T.unsafe(nil), logger: T.unsafe(nil), **args, &block); end
  end
end

# Allow any appender to run asynchronously in a separate thread.
class SemanticLogger::Appender::Async
  extend ::Forwardable

  # Appender proxy to allow an existing appender to run asynchronously in a separate thread.
  #
  # Parameters:
  # max_queue_size: [Integer]
  # The maximum number of log messages to hold on the queue before blocking attempts to add to the queue.
  # -1: The queue size is uncapped and will never block no matter how long the queue is.
  # Default: 10,000
  #
  # lag_threshold_s [Float]
  # Log a warning when a log message has been on the queue for longer than this period in seconds.
  # Default: 30
  #
  # lag_check_interval: [Integer]
  # Number of messages to process before checking for slow logging.
  # Default: 1,000
  def initialize(appender:, max_queue_size: T.unsafe(nil), lag_check_interval: T.unsafe(nil), lag_threshold_s: T.unsafe(nil)); end

  # Returns true if the worker thread is active
  def active?; end

  # Returns the value of attribute appender.
  def appender; end

  def application(*args, &block); end

  # Returns [true|false] if the queue has a capped size.
  def capped?; end

  # Close all appenders and flush any outstanding messages.
  def close; end

  def environment(*args, &block); end
  def filter(*args, &block); end

  # Flush all queued log entries disk, database, etc.
  # All queued log messages are written and then each appender is flushed in turn.
  def flush; end

  def host(*args, &block); end

  # Returns the value of attribute lag_check_interval.
  def lag_check_interval; end

  # Sets the attribute lag_check_interval
  def lag_check_interval=(_arg0); end

  # Returns the value of attribute lag_threshold_s.
  def lag_threshold_s; end

  # Sets the attribute lag_threshold_s
  def lag_threshold_s=(_arg0); end

  def level(*args, &block); end
  def level=(*args, &block); end

  # Add log message for processing.
  def log(log); end

  def logger(*args, &block); end
  def logger=(*args, &block); end

  # Returns the value of attribute max_queue_size.
  def max_queue_size; end

  def name(*args, &block); end

  # Returns the value of attribute queue.
  def queue; end

  # Re-open appender after a fork
  def reopen; end

  def should_log?(*args, &block); end

  # Returns [Thread] the worker thread.
  #
  # Starts the worker thread if not running.
  def thread; end

  private

  def check_lag(log); end
  def create_queue; end

  # Separate thread for batching up log messages before writing.
  def process; end

  # Returns false when message processing should be stopped
  def process_message(message); end

  def process_messages; end

  # Submit command and wait for reply
  def submit_request(command); end
end

# Log asynchronously in batches using a separate thread.
#
# Log messages are grouped up and only logged when:
# * The number of queued messages is exceeded.
# * Or, the appropriate amount of time has passed since the last batch was sent.
class SemanticLogger::Appender::AsyncBatch < ::SemanticLogger::Appender::Async
  # Batching Appender proxy for appenders that support batches.
  #
  # Parameters:
  # batch_size: [Integer]
  # Maximum number of messages to batch up before sending.
  # Default: 300
  #
  # batch_seconds: [Integer]
  # Maximum number of seconds between sending batches.
  # Default: 5
  #
  # See SemanticLogger::Appender::Async for other paramaters
  #
  # Note:
  # * `lag_check_interval` is not applicable to batches, since the first message of every batch
  # is the oldest and is always checked to see if the lag interval has been exceeded.
  def initialize(appender:, max_queue_size: T.unsafe(nil), lag_threshold_s: T.unsafe(nil), batch_size: T.unsafe(nil), batch_seconds: T.unsafe(nil)); end

  # Returns the value of attribute batch_seconds.
  def batch_seconds; end

  # Sets the attribute batch_seconds
  def batch_seconds=(_arg0); end

  # Returns the value of attribute batch_size.
  def batch_size; end

  # Sets the attribute batch_size
  def batch_size=(_arg0); end

  # Add log message for processing.
  def log(log); end

  # Returns the value of attribute signal.
  def signal; end

  private

  # Separate thread for batching up log messages before writing.
  def process_messages; end

  def submit_request(command); end
end

class SemanticLogger::Appender::ElasticsearchHttp < ::SemanticLogger::Appender::Http
  # Create Elasticsearch appender over persistent HTTP(S)
  #
  # Parameters:
  # index: [String]
  # Prefix of the index to store the logs in Elasticsearch.
  # The final index appends the date so that indexes are used per day.
  # I.e. The final index will look like 'semantic_logger-YYYY.MM.DD'
  # Default: 'semantic_logger'
  #
  # type: [String]
  # Document type to associate with logs when they are written.
  # Default: 'log'
  #
  # level: [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # formatter: [Object|Proc|Symbol|Hash]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this appender
  # Default: Use the built-in formatter (See: #call)
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied.
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # host: [String]
  # Name of this host to appear in log messages.
  # Default: SemanticLogger.host
  #
  # application: [String]
  # Name of this application to appear in log messages.
  # Default: SemanticLogger.application
  def initialize(index: T.unsafe(nil), type: T.unsafe(nil), url: T.unsafe(nil), **http_args, &block); end

  # Deletes all log data captured for a day.
  def delete_all(date = T.unsafe(nil)); end

  # Returns the value of attribute index.
  def index; end

  # Sets the attribute index
  def index=(_arg0); end

  # Log to the index for today.
  def log(log); end

  # Returns the value of attribute type.
  def type; end

  # Sets the attribute type
  def type=(_arg0); end
end

class SemanticLogger::Appender::File < ::SemanticLogger::Subscriber
  # Create an appender to log to a named file.
  #
  # Parameters
  # file_name [String]
  # Name of the file to write to.
  #
  # File name format directives:
  # %p - Process Id
  # %n - Short hostname (SemanticLogger.host). Everything before the first period in the hostname.
  # %N - Full hostname (SemanticLogger.host)
  # %a - Application name (SemanticLogger.application)
  # %e - Environment name (SemanticLogger.environment)
  # %D - Current Date. Equivalent to "%Y%m%d"
  # %T - Current Time. Equivalent to "%H%M%S"
  # %% - Literal `%` character
  #
  # Date:
  # %Y - Year with century
  # %C - year / 100 (round down.  20 in 2009)
  # %y - year % 100 (00..99)
  # %m - Month of the year, zero-padded (01..12)
  # %d - Day of the month, zero-padded (01..31)
  # %j - Day of the year (001..366)
  # %U - Week number of the year.  The week starts with Sunday.  (00..53)
  # %W - Week number of the year.  The week starts with Monday.  (00..53)
  #
  # Time:
  # %H - 24 Hour of the day, zero-padded (00..23)
  # %M - Minute of the hour (00..59)
  # %S - Second of the minute (00..60)
  #
  # Examples:
  # Create a log file name consisting of the short host name, process id, date, and time.
  # "log/production-%n-%p-%D-%T.log"
  #
  # :level [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # :formatter: [Object|Proc]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this appender
  # Default: Use the built-in formatter (See: #call)
  #
  # :filter [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # :append [true|false]
  # Append to the log file if already present?
  # Default: true
  #
  # :exclusive_lock [true|false]
  # Obtain an exclusive lock on the file, for operating systems that support it.
  # Prevents multiple processes from trying to write to the same log file.
  # Default: false
  #
  # :encoding ["UTF-8", "UTF-16", etc.]
  # Encoding to use when writing to the file.
  # Default: Encoding::BINARY
  #
  # :retry_count [Integer]
  # Number of times to attempt to re-open the file name when an error occurs trying to
  # write to the file.
  # Note: Set to 0 to disable retries.
  # Default: 1
  #
  # :reopen_period [String]
  # Specify a period after which to re-open the log file, specified in minutes, hours, or days.
  # The format of the duration must start with an Integer or Float number,
  # followed by the duration specified as:
  # "m" : minutes
  # "h" : hours
  # "d" : days
  # The time is rounded down to the specified time interval, so that:
  # - "1h" will re-open every hour at the beginning of the hour.
  # - "30m" will re-open every 30 minutes at the beginning of the 30th minute.
  # - "1d" will re-open every day at midnight.
  # Examples:
  # "60m" : Every 60 minutes at the beginning of the minute: 10:24:00, 11:24:00, 12:24:00, ...
  # "1h"  : Every hour at the beginning of the hour: 10:00:00, 11:00:00, 12:00:00, ...
  # "1d"  : Every day at the beginning of the day: "20211008 00:00:00", "20211009 00:00:00", ...
  # Default: nil (Disabled)
  #
  # :reopen_count [Integer]
  # Close and re-open the log file after every `reopen_count` number of logged entries.
  # Default: 0 (Disabled)
  #
  # :reopen_size [Integer]
  # Approximate number of bytes to write to a log file by this process before closing and re-opening it.
  # Notes:
  # - When `append: true` and the file already exists, it reads the size of the current log file
  # and starts with that size.
  # - If the current log file size already exceeds the `reopen_size`, its current size is ignored.
  # - The `reopen_size` is only the amount of bytes written by this process, it excludes data
  # written by other processes. Use a unique filename to prevent multiple processes from writing to
  # the same log file at the same time.
  # Default: 0 (Disabled)
  #
  # Example
  # require "semantic_logger"
  #
  # # Enable trace level logging
  # SemanticLogger.default_level = :info
  #
  # # Log to a file
  # SemanticLogger.add_appender(file_name: "application.log", formatter: :color)
  #
  # logger = SemanticLogger["test"]
  # logger.info "Hello World"
  def initialize(file_name, retry_count: T.unsafe(nil), append: T.unsafe(nil), reopen_period: T.unsafe(nil), reopen_count: T.unsafe(nil), reopen_size: T.unsafe(nil), encoding: T.unsafe(nil), exclusive_lock: T.unsafe(nil), **args, &block); end

  # Returns the value of attribute append.
  def append; end

  # Sets the attribute append
  def append=(_arg0); end

  # Returns the value of attribute current_file_name.
  def current_file_name; end

  # Returns the value of attribute encoding.
  def encoding; end

  # Sets the attribute encoding
  def encoding=(_arg0); end

  # Returns the value of attribute exclusive_lock.
  def exclusive_lock; end

  # Sets the attribute exclusive_lock
  def exclusive_lock=(_arg0); end

  # Returns the value of attribute file_name.
  def file_name; end

  # Sets the attribute file_name
  def file_name=(_arg0); end

  # Flush all pending logs to disk.
  # Waits for all sent documents to be written to disk
  def flush; end

  # Since only one appender thread will be writing to the file at a time
  # it is not necessary to protect access to the file with a semaphore.
  def log(log); end

  # Returns the value of attribute log_count.
  def log_count; end

  # Returns the value of attribute log_size.
  def log_size; end

  # After forking an active process call #reopen to re-open
  # open the file handles etc to resources.
  def reopen; end

  # Returns the value of attribute reopen_at.
  def reopen_at; end

  # Returns the value of attribute reopen_count.
  def reopen_count; end

  # Sets the attribute reopen_count
  def reopen_count=(_arg0); end

  # Returns the value of attribute reopen_period.
  def reopen_period; end

  # Sets the attribute reopen_period
  def reopen_period=(_arg0); end

  # Returns the value of attribute reopen_size.
  def reopen_size; end

  # Sets the attribute reopen_size
  def reopen_size=(_arg0); end

  # Returns the value of attribute retry_count.
  def retry_count; end

  # Sets the attribute retry_count
  def retry_count=(_arg0); end

  private

  def apply_format_directives(file_name); end

  # Round down the current time based on the period, then add on the duration for that period
  def calculate_reopen_at(duration, period, time = T.unsafe(nil)); end

  # Sets the attribute current_file_name
  def current_file_name=(_arg0); end

  def format_directive(directive); end

  # Sets the attribute log_count
  def log_count=(_arg0); end

  # Sets the attribute log_size
  def log_size=(_arg0); end

  def next_reopen_period(period_string); end
  def parse_period(period_string); end

  # Sets the attribute reopen_at
  def reopen_at=(_arg0); end

  def time_to_reopen?; end
end

class SemanticLogger::Appender::Http < ::SemanticLogger::Subscriber
  # Create HTTP(S) log appender
  #
  # Parameters:
  # url: [String]
  # Valid URL to post to.
  # Example: http://example.com/some_path
  # To enable SSL include https in the URL.
  # Example: https://example.com/some_path
  # verify_mode will default: OpenSSL::SSL::VERIFY_PEER
  #
  # application: [String]
  # Name of this application to appear in log messages.
  # Default: SemanticLogger.application
  #
  # host: [String]
  # Name of this host to appear in log messages.
  # Default: SemanticLogger.host
  #
  # username: [String]
  # User name for basic Authentication.
  # Default: nil ( do not use basic auth )
  #
  # password: [String]
  # Password for basic Authentication.
  #
  # compress: [true|false]
  # Whether to compress the JSON string with GZip.
  # Default: false
  #
  # ssl: [Hash]
  # Specific SSL options: For more details see NET::HTTP.start
  # ca_file, ca_path, cert, cert_store, ciphers, key, ssl_timeout,
  # ssl_version, verify_callback, verify_depth and verify_mode.
  #
  # level: [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # formatter: [Object|Proc]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this appender
  # Default: Use the built-in formatter (See: #call)
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied.
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # open_timeout: [Float]
  # Default: 2.0
  #
  # read_timeout: [Float]
  # Default: 1.0
  #
  # continue_timeout: [Float]
  # Default: 1.0
  def initialize(url:, compress: T.unsafe(nil), ssl: T.unsafe(nil), username: T.unsafe(nil), password: T.unsafe(nil), open_timeout: T.unsafe(nil), read_timeout: T.unsafe(nil), continue_timeout: T.unsafe(nil), **args, &block); end

  # Returns the value of attribute compress.
  def compress; end

  # Sets the attribute compress
  def compress=(_arg0); end

  # Returns the value of attribute continue_timeout.
  def continue_timeout; end

  # Sets the attribute continue_timeout
  def continue_timeout=(_arg0); end

  # Returns the value of attribute header.
  def header; end

  # Sets the attribute header
  def header=(_arg0); end

  # Returns the value of attribute http.
  def http; end

  # Forward log messages to HTTP Server
  def log(log); end

  # Returns the value of attribute open_timeout.
  def open_timeout; end

  # Sets the attribute open_timeout
  def open_timeout=(_arg0); end

  # Returns the value of attribute path.
  def path; end

  # Returns the value of attribute port.
  def port; end

  # Returns the value of attribute read_timeout.
  def read_timeout; end

  # Sets the attribute read_timeout
  def read_timeout=(_arg0); end

  # Re-open after process fork
  def reopen; end

  # Returns the value of attribute server.
  def server; end

  # Returns the value of attribute ssl_options.
  def ssl_options; end

  # Returns the value of attribute url.
  def url; end

  # Returns the value of attribute username.
  def username; end

  # Sets the attribute username
  def username=(_arg0); end

  private

  def compress_data(data); end

  # Use JSON Formatter by default
  def default_formatter; end

  # HTTP Delete
  def delete(request_uri = T.unsafe(nil)); end

  # HTTP Post
  def post(body, request_uri = T.unsafe(nil)); end

  # Process HTTP Request
  def process_request(request, body = T.unsafe(nil)); end

  # HTTP Put
  def put(body, request_uri = T.unsafe(nil)); end
end

class SemanticLogger::Appender::IO < ::SemanticLogger::Subscriber
  # Create a Stream Logger appender instance.
  #
  # Parameters
  # io [IO]
  # An IO stream to which to write the log messages to.
  #
  # :level [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # :formatter: [Object|Proc]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this appender
  # Default: Use the built-in formatter (See: #call)
  #
  # :filter [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # Example
  # require "semantic_logger"
  #
  # # Enable trace level logging
  # SemanticLogger.default_level = :info
  #
  # # Log to screen
  # SemanticLogger.add_appender(io: $stdout, formatter: :color)
  #
  # logger = SemanticLogger['test']
  # logger.info 'Hello World'
  def initialize(io, **args, &block); end

  def console_output?; end

  # Flush all pending logs to disk.
  # Waits for all sent documents to be written to disk
  def flush; end

  def log(log); end
end

class SemanticLogger::Appender::SplunkHttp < ::SemanticLogger::Appender::Http
  # Create Splunk appender over persistent HTTP(S)
  #
  # Parameters:
  # token: [String]
  # Token created in Splunk for this HTTP Appender
  # Mandatory.
  #
  # source_type: [String]
  # Optional: Source type to display in Splunk
  #
  # index: [String]
  # Optional: Name of a valid index for this message in Splunk.
  #
  # url: [String]
  # Valid URL to post to.
  # Example: http://example.com
  # To enable SSL include https in the URL.
  # Example: https://example.com
  # verify_mode will default: OpenSSL::SSL::VERIFY_PEER
  #
  # application: [String]
  # Name of this application to appear in log messages.
  # Default: SemanticLogger.application
  #
  # host: [String]
  # Name of this host to appear in log messages.
  # Default: SemanticLogger.host
  #
  # compress: [true|false]
  # Splunk supports HTTP Compression, enable by default.
  # Default: true
  #
  # ssl: [Hash]
  # Specific SSL options: For more details see NET::HTTP.start
  # ca_file, ca_path, cert, cert_store, ciphers, key, open_timeout, read_timeout, ssl_timeout,
  # ssl_version, use_ssl, verify_callback, verify_depth and verify_mode.
  #
  # level: [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # formatter: [Object|Proc]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this appender
  # Default: Use the built-in formatter (See: #call)
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied.
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  def initialize(token: T.unsafe(nil), source_type: T.unsafe(nil), index: T.unsafe(nil), compress: T.unsafe(nil), **args, &block); end

  # Returns [String] JSON to send to Splunk.
  #
  # For splunk format requirements see:
  # https://docs.splunk.com/Documentation/Splunk/latest/Data/FormateventsforHTTPEventCollector
  def call(log, logger); end

  # Returns the value of attribute index.
  def index; end

  # Sets the attribute index
  def index=(_arg0); end

  # Returns the value of attribute source_type.
  def source_type; end

  # Sets the attribute source_type
  def source_type=(_arg0); end
end

class SemanticLogger::Appender::Syslog < ::SemanticLogger::Subscriber
  # Create a Syslog appender instance.
  #
  # Parameters
  # url: [String]
  # Default: 'syslog://localhost'
  # For writing logs to a remote syslog server
  # URL of server: protocol://host:port
  # Uses port 514 by default for TCP and UDP.
  # local syslog example:          'syslog://localhost'
  # TCP example with default port: 'tcp://logger'
  # TCP example with custom port:  'tcp://logger:8514'
  # UDP example with default port: 'udp://logger'
  # UDP example with custom port:  'udp://logger:8514'
  # When using the :syslog protocol, logs will always be sent to the localhost syslog
  #
  # host: [String]
  # Host name to provide to the remote syslog.
  # Default: SemanticLogger.host
  #
  # tcp_client: [Hash]
  # Default: {}
  # Only used with the TCP protocol.
  # Specify custom parameters to pass into Net::TCPClient.new
  # For a list of options see the net_tcp_client documentation:
  # https://github.com/reidmorrison/net_tcp_client/blob/master/lib/net/tcp_client/tcp_client.rb
  #
  # level: [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied.
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # application: [String]
  # Identity of the program.
  # Default: SemanticLogger.application
  #
  # max_size: [Integer]
  # Set your own packet size.
  # Default: 1024 bytes
  #
  # options: [Integer]
  # Default: ::Syslog::LOG_PID | ::Syslog::LOG_CONS
  # Any of the following (options can be logically OR'd together)
  # ::Syslog::LOG_CONS
  # ::Syslog::LOG_NDELAY
  # ::Syslog::LOG_NOWAIT
  # ::Syslog::LOG_ODELAY
  # ::Syslog::LOG_PERROR
  # ::Syslog::LOG_PID
  # Note:
  # - Only applicable when logging to a local syslog instance.
  # I.e. When `url: 'syslog://localhost'`
  #
  # facility: [Integer]
  # Default: ::Syslog::LOG_USER
  # Type of program (can be logically OR'd together)
  # ::Syslog::LOG_AUTH
  # ::Syslog::LOG_AUTHPRIV
  # ::Syslog::LOG_CONSOLE
  # ::Syslog::LOG_CRON
  # ::Syslog::LOG_DAEMON
  # ::Syslog::LOG_FTP
  # ::Syslog::LOG_KERN
  # ::Syslog::LOG_LRP
  # ::Syslog::LOG_MAIL
  # ::Syslog::LOG_NEWS
  # ::Syslog::LOG_NTP
  # ::Syslog::LOG_SECURITY
  # ::Syslog::LOG_SYSLOG
  # ::Syslog::LOG_USER
  # ::Syslog::LOG_UUCP
  # ::Syslog::LOG_LOCAL0
  # ::Syslog::LOG_LOCAL1
  # ::Syslog::LOG_LOCAL2
  # ::Syslog::LOG_LOCAL3
  # ::Syslog::LOG_LOCAL4
  # ::Syslog::LOG_LOCAL5
  # ::Syslog::LOG_LOCAL6
  # ::Syslog::LOG_LOCAL7
  #
  # level_map: [Hash | SemanticLogger::Formatters::Syslog::LevelMap]
  # Supply a custom map of SemanticLogger levels to syslog levels.
  #
  # Example:
  # # Change the warn level to LOG_NOTICE level instead of a the default of LOG_WARNING.
  # SemanticLogger.add_appender(appender: :syslog, level_map: {warn: ::Syslog::LOG_NOTICE})
  def initialize(url: T.unsafe(nil), facility: T.unsafe(nil), max_size: T.unsafe(nil), level_map: T.unsafe(nil), options: T.unsafe(nil), tcp_client: T.unsafe(nil), **args, &block); end

  # Returns [SemanticLogger::Formatters::Base] default formatter for this Appender depending on the protocal selected
  def default_formatter; end

  # Returns the value of attribute facility.
  def facility; end

  # Flush is called by the semantic_logger during shutdown.
  def flush; end

  # Returns the value of attribute level_map.
  def level_map; end

  # Write the log using the specified protocol and server.
  def log(log); end

  # Returns the value of attribute max_size.
  def max_size; end

  # Returns the value of attribute options.
  def options; end

  # Returns the value of attribute port.
  def port; end

  # Returns the value of attribute protocol.
  def protocol; end

  # Returns the value of attribute remote_syslog.
  def remote_syslog; end

  # After forking an active process call #reopen to re-open
  # open the handles to resources
  def reopen; end

  # Returns the value of attribute server.
  def server; end

  # Returns the value of attribute url.
  def url; end
end

# UDP log appender.
#
# Write log messages to UDP.
# By default messages are in JSON format.
#
# Example:
# SemanticLogger.add_appender(
# appender: :udp,
# server:   'server:3300',
# )
class SemanticLogger::Appender::Udp < ::SemanticLogger::Subscriber
  # Create UDP log appender.
  #
  # server: [String]
  # URL of the server to write UDP messages to.
  #
  # udp_flags: [Integer]
  # Should be a bitwise OR of Socket::MSG_* constants.
  # Default: 0
  #
  # Common Appender Parameters:
  # application: [String]
  # Name of this application to appear in log messages.
  # Default: SemanticLogger.application
  #
  # host: [String]
  # Name of this host to appear in log messages.
  # Default: SemanticLogger.host
  #
  # level: [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # formatter: [Object|Proc]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this appender
  # Default: Use the built-in formatter (See: #call)
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied.
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # metrics: [Boolean]
  # Send metrics only events over udp.
  # Default: true
  #
  # Limitations:
  # * UDP packet size is limited by the connected network and any routers etc
  # that the message has to traverse. See https://en.wikipedia.org/wiki/Maximum_transmission_unit
  #
  # Example:
  # SemanticLogger.add_appender(
  # appender: :udp,
  # server:   'server:3300'
  # )
  def initialize(server:, udp_flags: T.unsafe(nil), metrics: T.unsafe(nil), **args, &block); end

  # Close is called during shutdown, or with reopen
  def close; end

  # Flush is called by the semantic_logger during shutdown.
  def flush; end

  # Write the log using the specified protocol and server.
  def log(log); end

  # After forking an active process call #reopen to re-open
  # open the handles to resources
  def reopen; end

  # Returns the value of attribute server.
  def server; end

  # Sets the attribute server
  def server=(_arg0); end

  # Returns the value of attribute socket.
  def socket; end

  # Returns the value of attribute udp_flags.
  def udp_flags; end

  # Sets the attribute udp_flags
  def udp_flags=(_arg0); end

  private

  # Returns [SemanticLogger::Formatters::Default] formatter default for this Appender
  def default_formatter; end
end

class SemanticLogger::Appender::Wrapper < ::SemanticLogger::Subscriber
  # Forward all logging calls to the supplied logging instance.
  #
  # Parameters
  # logger: [Object]
  # Instance of an existing logger conforming to the Ruby Logger methods.
  #
  # level: [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this appender.
  # Default: SemanticLogger.default_level
  #
  # formatter: [Object|Proc]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this appender
  # Default: Use the built-in formatter (See: #call)
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied.
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # Ruby Logger
  # require 'logger'
  # require 'semantic_logger'
  #
  # ruby_logger = Logger.new($stdout)
  # SemanticLogger.add_appender(logger: ruby_logger)
  #
  # logger =  SemanticLogger['test']
  # logger.info('Hello World', some: :payload)
  #
  # Install the `rails_semantic_logger` gem to replace the Rails logger with Semantic Logger.
  def initialize(logger:, **args, &block); end

  # Flush all pending logs to disk.
  # Waits for all sent documents to be writted to disk
  def flush; end

  # Pass log calls to the underlying Rails, log4j or Ruby logger
  # trace entries are mapped to debug since :trace is not supported by the
  # Ruby or Rails Loggers
  def log(log); end

  # Returns the value of attribute logger.
  def logger; end
end

# Manage a collection of appenders.
class SemanticLogger::Appenders < ::Concurrent::Array
  def initialize(logger = T.unsafe(nil)); end

  def add(**args, &block); end
  def close; end

  # Whether any of the existing appenders already output to the console?
  # I.e. Writes to stdout or stderr.
  def console_output?; end

  def flush; end
  def log(log); end

  # Returns the value of attribute logger.
  def logger; end

  # Sets the attribute logger
  def logger=(_arg0); end

  # After a fork the appender thread is not running, start it if it is not running.
  def reopen; end
end

class SemanticLogger::Base
  # Initializer for Abstract Class SemanticLogger::Base
  #
  # Parameters
  # klass [String]
  # Name of the class, module, or other identifier for which the log messages
  # are being logged
  #
  # level [Symbol]
  # Only allow log entries of this level or higher to be written to this appender
  # For example if set to :warn, this appender would only log :warn and :fatal
  # log messages when other appenders could be logging :info and lower
  #
  # filter [Regexp|Proc|Module]
  # RegExp: Only include log messages where the class name matches the supplied
  # regular expression. All other messages will be ignored
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false
  # Module: A module that implements `.call`. For example:
  # module ComplexFilter
  # def self.call(log)
  # (/\AExclude/ =~ log.message).nil?
  # end
  # end
  def initialize(klass, level = T.unsafe(nil), filter = T.unsafe(nil)); end

  # Log a thread backtrace
  def backtrace(thread: T.unsafe(nil), level: T.unsafe(nil), message: T.unsafe(nil), payload: T.unsafe(nil), metric: T.unsafe(nil), metric_amount: T.unsafe(nil)); end

  # Dynamically supply the log level with every measurement call
  # Backward compatibility
  def benchmark(level, message, params = T.unsafe(nil), &block); end

  def benchmark_debug(message, params = T.unsafe(nil), &block); end
  def benchmark_error(message, params = T.unsafe(nil), &block); end
  def benchmark_fatal(message, params = T.unsafe(nil), &block); end
  def benchmark_info(message, params = T.unsafe(nil), &block); end
  def benchmark_trace(message, params = T.unsafe(nil), &block); end
  def benchmark_warn(message, params = T.unsafe(nil), &block); end
  def debug(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def debug?; end
  def error(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def error?; end
  def fast_tag(tag, &block); end
  def fatal(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def fatal?; end

  # Class name to be logged
  def filter; end

  # Class name to be logged
  def filter=(_arg0); end

  def info(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def info?; end

  # Returns the current log level if set, otherwise it returns the global
  # default log level
  def level; end

  # Set the logging level for this logger
  #
  # Note: This level is only for this particular instance. It does not override
  # the log level in any logging instance or the default log level
  # SemanticLogger.default_level
  #
  # Must be one of the values in SemanticLogger::LEVELS, or
  # nil if this logger instance should use the global default level
  def level=(level); end

  # Write log data to underlying data storage
  def log(_log_); end

  # Dynamically supply the log level with every measurement call
  def measure(level, message, params = T.unsafe(nil), &block); end

  def measure_debug(message, params = T.unsafe(nil), &block); end
  def measure_error(message, params = T.unsafe(nil), &block); end
  def measure_fatal(message, params = T.unsafe(nil), &block); end
  def measure_info(message, params = T.unsafe(nil), &block); end
  def measure_trace(message, params = T.unsafe(nil), &block); end
  def measure_warn(message, params = T.unsafe(nil), &block); end

  # Class name to be logged
  def name; end

  # Class name to be logged
  def name=(_arg0); end

  def named_tags; end
  def pop_tags(quantity = T.unsafe(nil)); end

  # Returns the list of tags pushed after flattening them out and removing blanks
  #
  # Note:
  # - This method is slow since it needs to flatten the tags and remove empty elements
  # to support Rails 4.
  # - For better performance with clean tags, use `SemanticLogger.push_tags`
  def push_tags(*tags); end

  # Whether this log entry meets the criteria to be logged by this appender.
  def should_log?(log); end

  def silence(new_level = T.unsafe(nil), &block); end

  # Add the tags or named tags to the list of tags to log for this thread whilst the supplied block is active.
  #
  # Returns result of block.
  #
  # Tagged example:
  # SemanticLogger.tagged(12345, 'jack') do
  # logger.debug('Hello World')
  # end
  #
  # Named Tags (Hash) example:
  # SemanticLogger.tagged(tracking_number: 12345) do
  # logger.debug('Hello World')
  # end
  #
  # Notes:
  # - Named tags are the recommended approach since the tag consists of a name value pair this is more useful
  # than just a string value in the logs, or centralized logging system.
  # - This method is slow when using multiple text tags since it needs to flatten the tags and
  # remove empty elements to support Rails 4.
  # - It is recommended to keep tags as a list without any empty values, or contain any child arrays.
  # However, this api will convert:
  # `logger.tagged([['first', nil], nil, ['more'], 'other'])`
  # to:
  # `logger.tagged('first', 'more', 'other')`
  # - For better performance with clean tags, see `SemanticLogger.tagged`.
  def tagged(*tags, &block); end

  def tags; end
  def trace(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def trace?; end
  def warn(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def warn?; end

  # Add the tags or named tags to the list of tags to log for this thread whilst the supplied block is active.
  #
  # Returns result of block.
  #
  # Tagged example:
  # SemanticLogger.tagged(12345, 'jack') do
  # logger.debug('Hello World')
  # end
  #
  # Named Tags (Hash) example:
  # SemanticLogger.tagged(tracking_number: 12345) do
  # logger.debug('Hello World')
  # end
  #
  # Notes:
  # - Named tags are the recommended approach since the tag consists of a name value pair this is more useful
  # than just a string value in the logs, or centralized logging system.
  # - This method is slow when using multiple text tags since it needs to flatten the tags and
  # remove empty elements to support Rails 4.
  # - It is recommended to keep tags as a list without any empty values, or contain any child arrays.
  # However, this api will convert:
  # `logger.tagged([['first', nil], nil, ['more'], 'other'])`
  # to:
  # `logger.tagged('first', 'more', 'other')`
  # - For better performance with clean tags, see `SemanticLogger.tagged`.
  def with_tags(*tags, &block); end

  private

  # Whether to log the supplied message based on the current filter if any
  def filtered?(log); end

  # Return the level index for fast comparisons
  # Returns the global default level index if the level has not been explicitly
  # set for this instance
  def level_index; end

  # Log message at the specified level
  def log_internal(level, index, message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil)); end

  # Measure the supplied block and log the message
  def measure_internal(level, index, message, params); end

  # For measuring methods and logging their duration.
  def measure_method(index:, level:, message:, min_duration:, metric:, log_exception:, on_exception_level:); end

  # Ensure minimum log level is met
  def meets_log_level?(log); end
end

module SemanticLogger::Concerns; end

module SemanticLogger::Concerns::Compatibility
  def add(severity, message = T.unsafe(nil), progname = T.unsafe(nil), &block); end
  def close; end
  def reopen(logdev = T.unsafe(nil)); end

  class << self
    # For compatibility with Ruby Logger only.
    def included(base); end
  end
end

# Custom logger that maps all calls to debug to trace calls
# This is useful for existing gems / libraries that log too much to debug
# when most of the debug logging should be at the trace level
class SemanticLogger::DebugAsTraceLogger < ::SemanticLogger::Logger
  def benchmark_debug(*args, &block); end
  def debug(*args, &block); end
  def debug?; end
  def measure_debug(*args, &block); end
end

module SemanticLogger::Formatters
  class << self
    # Return formatter that responds to call.
    #
    # Supports formatter supplied as:
    # - Symbol
    # - Hash ( Symbol => { options })
    # - Instance of any of SemanticLogger::Formatters
    # - Proc
    # - Any object that responds to :call
    def factory(formatter); end
  end
end

class SemanticLogger::Formatters::Base
  # Parameters
  # time_format: [String|Symbol|nil]
  # See Time#strftime for the format of this string.
  # :iso_8601 Outputs an ISO8601 Formatted timestamp.
  # :ms       Output in miliseconds since epoch.
  # nil:      Returns Empty string for time ( no time is output ).
  # Default: '%Y-%m-%d %H:%M:%S.%<precision>N'
  # log_host: [Boolean]
  # Whether or not to include hostname in logs
  # Default: true
  # log_application: [Boolean]
  # Whether or not to include application name in logs
  # Default: true
  # precision: [Integer]
  # How many fractional digits to log times with.
  # Default: PRECISION (6, except on older JRuby, where 3)
  def initialize(time_format: T.unsafe(nil), log_host: T.unsafe(nil), log_application: T.unsafe(nil), log_environment: T.unsafe(nil), precision: T.unsafe(nil)); end

  # Returns the value of attribute log.
  def log; end

  # Sets the attribute log
  def log=(_arg0); end

  # Returns the value of attribute log_application.
  def log_application; end

  # Sets the attribute log_application
  def log_application=(_arg0); end

  # Returns the value of attribute log_environment.
  def log_environment; end

  # Sets the attribute log_environment
  def log_environment=(_arg0); end

  # Returns the value of attribute log_host.
  def log_host; end

  # Sets the attribute log_host
  def log_host=(_arg0); end

  # Returns the value of attribute logger.
  def logger; end

  # Sets the attribute logger
  def logger=(_arg0); end

  # Process ID
  def pid; end

  # Returns the value of attribute precision.
  def precision; end

  # Sets the attribute precision
  def precision=(_arg0); end

  # Date & time
  def time; end

  # Returns the value of attribute time_format.
  def time_format; end

  # Sets the attribute time_format
  def time_format=(_arg0); end

  private

  # Return the Time as a formatted string
  def format_time(time); end

  class << self
    # Return default time format string
    #
    # Parameters
    # precision: [Integer]
    # How many fractional digits to log times with.
    # Default: PRECISION (6, except on older JRuby, where 3)
    def build_time_format(precision = T.unsafe(nil)); end
  end
end

# Time precision varies by Ruby interpreter
# JRuby 9.1.8.0 supports microseconds
SemanticLogger::Formatters::Base::PRECISION = T.let(T.unsafe(nil), Integer)

class SemanticLogger::Formatters::Color < ::SemanticLogger::Formatters::Default
  # Adds color to the default log formatter
  #
  # Example:
  # # Use a colorized output logger.
  # SemanticLogger.add_appender(io: $stdout, formatter: :color)
  #
  # Example:
  # # Use a colorized output logger changing the color for info to yellow.
  # SemanticLogger.add_appender(io: $stdout, formatter: {color: {color_map: {info: SemanticLogger::AnsiColors::YELLOW}}})
  #
  # Example:
  # # Override the Awesome Print options to output hashes over multiple lines:
  # SemanticLogger.add_appender(io: $stdout, formatter: {color: {ap: {multiline: true}}})
  #
  # # Calling the appender added above:
  # SemanticLogger['Test'].info('hi', {a: 1, b: 2})
  # => true
  # => 2019-02-12 11:47:50.794339 I [35832:70112015269920] Test -- hi -- {
  # :a => 1,
  # :b => 2
  # }
  #
  # Parameters:
  # ap: [Hash]
  # Any valid Amazing Print option for rendering data.
  # These options can also be changed be creating a `~/.aprc` file.
  # See: https://github.com/amazing-print/amazing_print
  #
  # Note: The option :multiline is set to false if not supplied.
  # Note: Has no effect if Awesome Print is not installed.
  #
  # color_map: [Hash | SemanticLogger::Formatters::Color::ColorMap]
  # ColorMaps each of the log levels to a color
  def initialize(ap: T.unsafe(nil), color_map: T.unsafe(nil), **args); end

  def call(log, logger); end

  # Returns the value of attribute color.
  def color; end

  # Sets the attribute color
  def color=(_arg0); end

  # Returns the value of attribute color_map.
  def color_map; end

  # Sets the attribute color_map
  def color_map=(_arg0); end

  def duration; end
  def exception; end
  def level; end
  def name; end

  # Named Tags
  def named_tags; end

  def payload; end
  def tags; end
end

# Supply a custom color map for every log level
class SemanticLogger::Formatters::Color::ColorMap
  def initialize(trace: T.unsafe(nil), debug: T.unsafe(nil), info: T.unsafe(nil), warn: T.unsafe(nil), error: T.unsafe(nil), fatal: T.unsafe(nil), bold: T.unsafe(nil), clear: T.unsafe(nil)); end

  def [](level); end

  # Returns the value of attribute bold.
  def bold; end

  # Sets the attribute bold
  def bold=(_arg0); end

  # Returns the value of attribute clear.
  def clear; end

  # Sets the attribute clear
  def clear=(_arg0); end

  # Returns the value of attribute debug.
  def debug; end

  # Sets the attribute debug
  def debug=(_arg0); end

  # Returns the value of attribute error.
  def error; end

  # Sets the attribute error
  def error=(_arg0); end

  # Returns the value of attribute fatal.
  def fatal; end

  # Sets the attribute fatal
  def fatal=(_arg0); end

  # Returns the value of attribute info.
  def info; end

  # Sets the attribute info
  def info=(_arg0); end

  # Returns the value of attribute trace.
  def trace; end

  # Sets the attribute trace
  def trace=(_arg0); end

  # Returns the value of attribute warn.
  def warn; end

  # Sets the attribute warn
  def warn=(_arg0); end
end

# Default non-colored text log output
class SemanticLogger::Formatters::Default < ::SemanticLogger::Formatters::Base
  # Default text log format
  # Generates logs of the form:
  # 2011-07-19 14:36:15.660235 D [1149:ScriptThreadProcess] Rails -- Hello World
  def call(log, logger); end

  # Duration
  def duration; end

  # Exception
  def exception; end

  # Ruby file name and line number that logged the message.
  def file_name_and_line; end

  # Log level
  def level; end

  # Log message
  def message; end

  # Class / app name
  def name; end

  # Named Tags
  def named_tags; end

  # Payload
  def payload; end

  # Returns [String] the available process info
  # Example:
  # [18934:thread_name test_logging.rb:51]
  def process_info; end

  # Tags
  def tags; end

  # Name of the thread that logged the message.
  def thread_name; end
end

# Fluentd is similar to SemanticLogger::Formatters::Json but with log levels that are recognized
# by kubernetes fluentd.
class SemanticLogger::Formatters::Fluentd < ::SemanticLogger::Formatters::Json
  def initialize(time_format: T.unsafe(nil), time_key: T.unsafe(nil), need_process_info: T.unsafe(nil), **args); end

  def level; end

  # Returns the value of attribute need_process_info.
  def need_process_info; end

  def process_info; end
end

class SemanticLogger::Formatters::Json < ::SemanticLogger::Formatters::Raw
  # Default JSON time format is ISO8601
  def initialize(time_format: T.unsafe(nil), time_key: T.unsafe(nil), **args); end

  # Returns log messages in JSON format
  def call(log, logger); end
end

# Produces logfmt formatted messages
#
# The following fields are extracted from the raw log and included in the formatted message:
# :timestamp, :level, :name, :message, :duration, :tags, :named_tags
#
# E.g.
# timestamp="2020-07-20T08:32:05.375276Z" level=info name="DefaultTest" base="breakfast" spaces="second breakfast" double_quotes="\"elevensies\"" single_quotes="'lunch'" tag="success"
#
# All timestamps are ISO8601 formatteed
# All user supplied values are escaped and surrounded by double quotes to avoid ambiguious message delimeters
# `tags` are treated as keys with boolean values. Tag names are not formatted or validated, ensure you use valid logfmt format for tag names.
# `named_tags` are flattened are merged into the top level message field. Any conflicting fields are overridden.
# `payload` values take precedence over `tags` and `named_tags`. Any conflicting fields are overridden.
#
# Futher Reading https://brandur.org/logfmt
class SemanticLogger::Formatters::Logfmt < ::SemanticLogger::Formatters::Raw
  def initialize(time_format: T.unsafe(nil), time_key: T.unsafe(nil), **args); end

  def call(log, logger); end

  private

  def flatten_log; end
  def handle_exception; end
  def handle_payload; end
  def handle_tags; end
  def raw_to_logfmt; end
end

# Only output one line for each log entry.
#
# Notes:
# * New lines are stripped from log messages.
# * Exceptions only include the class and message, the stack trace is not shown.
class SemanticLogger::Formatters::OneLine < ::SemanticLogger::Formatters::Default
  def exception; end
  def message; end
end

class SemanticLogger::Formatters::Raw < ::SemanticLogger::Formatters::Base
  # By default Raw formatter does not reformat the time
  def initialize(time_format: T.unsafe(nil), time_key: T.unsafe(nil), **args); end

  # Application name
  def application; end

  # Returns log messages in Hash format
  def call(log, logger); end

  # Duration
  def duration; end

  # Environment
  def environment; end

  # Exception
  def exception; end

  # Ruby file name and line number that logged the message.
  def file_name_and_line; end

  # Fields are added by populating this hash.
  def hash; end

  # Fields are added by populating this hash.
  def hash=(_arg0); end

  # Host name
  def host; end

  # Log level
  def level; end

  # Log message
  def message; end

  # Metric
  def metric; end

  # Class / app name
  def name; end

  # Named Tags
  def named_tags; end

  # Payload
  def payload; end

  # Process ID
  def pid; end

  # Tags
  def tags; end

  # Name of the thread that logged the message.
  def thread_name; end

  # Date & time
  def time; end

  # Fields are added by populating this hash.
  def time_key; end

  # Fields are added by populating this hash.
  def time_key=(_arg0); end
end

class SemanticLogger::Formatters::Signalfx < ::SemanticLogger::Formatters::Base
  def initialize(token:, dimensions: T.unsafe(nil), gauge_name: T.unsafe(nil), counter_name: T.unsafe(nil), time_format: T.unsafe(nil), **args); end

  # Returns [Hash] a batch of log messages.
  # Signalfx has a minimum resolution of 1 second.
  # Metrics of the same type, time (second), and dimensions can be aggregated together.
  def batch(logs, logger); end

  # Returns [Hash] log message in Signalfx format.
  def call(log, logger); end

  # Returns the value of attribute counter_name.
  def counter_name; end

  # Sets the attribute counter_name
  def counter_name=(_arg0); end

  # Returns the value of attribute dimensions.
  def dimensions; end

  # Sets the attribute dimensions
  def dimensions=(_arg0); end

  # Dimensions for this metric
  def format_dimensions; end

  # Returns the value of attribute gauge_name.
  def gauge_name; end

  # Sets the attribute gauge_name
  def gauge_name=(_arg0); end

  # Returns the value of attribute hash.
  def hash; end

  # Sets the attribute hash
  def hash=(_arg0); end

  # Create SignalFx friendly metric.
  # Strip leading '/'
  # Convert remaining '/' to '.'
  def metric; end

  # Date & time
  def time; end

  # Returns the value of attribute token.
  def token; end

  # Sets the attribute token
  def token=(_arg0); end

  # Value of this metric
  def value; end

  private

  # Sum counters with the same time (second), name, and dimensions.
  def add_counter(counters, metric); end

  def add_gauge(gauges, metric); end

  # Find Metrics with the same timestamp, metric name, and dimensions.
  def find_match(list, metric); end
end

# Logging levels in order of most detailed to most severe
SemanticLogger::LEVELS = T.let(T.unsafe(nil), Array)

module SemanticLogger::Levels
  class << self
    # Internal method to return the log level as an internal index
    # Also supports mapping the ::Logger levels to SemanticLogger levels
    def index(level); end

    # Returns the symbolic level for the supplied level index
    def level(level_index); end
  end
end

# Logging levels in order of most detailed to most severe
SemanticLogger::Levels::LEVELS = T.let(T.unsafe(nil), Array)

# Log
#
# Class to hold all log entry information
#
# level
# Log level of the supplied log call
# :trace, :debug, :info, :warn, :error, :fatal
#
# thread_name
# Name of the thread in which the logging call was called
#
# name
# Class name supplied to the logging instance
#
# message
# Text message to be logged
#
# payload
# Optional Hash or Ruby Exception object to be logged
#
# time
# The time at which the log entry was created
#
# duration
# The time taken to complete a measure call
#
# tags
# Any tags active on the thread when the log call was made
#
# level_index
# Internal index of the log level
#
# exception
# Ruby Exception object to log
#
# metric [Object]
# Object supplied when measure_x was called
#
# backtrace [Array<String>]
# The backtrace captured at source when the log level >= SemanticLogger.backtrace_level
#
# metric_amount [Numeric]
# Used for numeric or counter metrics.
# For example, the number of inquiries or, the amount purchased etc.
#
# context [Hash]
# Named contexts that were captured when the log entry was created.
class SemanticLogger::Log
  def initialize(name, level, index = T.unsafe(nil)); end

  # Assign named arguments to this log entry, supplying defaults where applicable
  #
  # Returns [true|false] whether this log entry should be logged
  #
  # Example:
  # logger.info(name: 'value')
  def assign(message: T.unsafe(nil), payload: T.unsafe(nil), min_duration: T.unsafe(nil), exception: T.unsafe(nil), metric: T.unsafe(nil), metric_amount: T.unsafe(nil), duration: T.unsafe(nil), backtrace: T.unsafe(nil), log_exception: T.unsafe(nil), on_exception_level: T.unsafe(nil), dimensions: T.unsafe(nil)); end

  # Assign known keys to self, all other keys to the payload.
  def assign_hash(hash); end

  # Returns the value of attribute backtrace.
  def backtrace; end

  # Sets the attribute backtrace
  def backtrace=(_arg0); end

  # Returns [String] the exception backtrace including all of the child / caused by exceptions
  def backtrace_to_s; end

  # Strip the standard Rails colorizing from the logged message
  def cleansed_message; end

  # Returns the value of attribute context.
  def context; end

  # Sets the attribute context
  def context=(_arg0); end

  # Returns the value of attribute dimensions.
  def dimensions; end

  # Sets the attribute dimensions
  def dimensions=(_arg0); end

  # Returns the value of attribute duration.
  def duration; end

  # Sets the attribute duration
  def duration=(_arg0); end

  # Returns [String] the duration in human readable form
  def duration_human; end

  def duration_to_s; end

  # Call the block for exception and any nested exception
  def each_exception; end

  # Returns the value of attribute exception.
  def exception; end

  # Sets the attribute exception
  def exception=(_arg0); end

  # Extract the arguments from a Hash Payload
  def extract_arguments(payload); end

  # Extract the filename and line number from the last entry in the supplied backtrace
  def extract_file_and_line(stack, short_name = T.unsafe(nil)); end

  # Returns [String, String] the file_name and line_number from the backtrace supplied
  # in either the backtrace or exception
  def file_name_and_line(short_name = T.unsafe(nil)); end

  # Returns the value of attribute level.
  def level; end

  # Sets the attribute level
  def level=(_arg0); end

  # Returns the value of attribute level_index.
  def level_index; end

  # Sets the attribute level_index
  def level_index=(_arg0); end

  # Returns [String] single character upper case log level
  def level_to_s; end

  # Returns the value of attribute message.
  def message; end

  # Sets the attribute message
  def message=(_arg0); end

  # Returns the value of attribute metric.
  def metric; end

  # Sets the attribute metric
  def metric=(_arg0); end

  # Returns the value of attribute metric_amount.
  def metric_amount; end

  # Sets the attribute metric_amount
  def metric_amount=(_arg0); end

  # A metric only event has a metric but no message or exception.
  def metric_only?; end

  # Returns the value of attribute name.
  def name; end

  # Sets the attribute name
  def name=(_arg0); end

  # Returns the value of attribute named_tags.
  def named_tags; end

  # Sets the attribute named_tags
  def named_tags=(_arg0); end

  # Returns the value of attribute payload.
  def payload; end

  # Sets the attribute payload
  def payload=(_arg0); end

  # Returns [true|false] whether the log entry has a payload
  def payload?; end

  # Return the payload in text form
  # Returns nil if payload is missing or empty
  def payload_to_s; end

  # DEPRECATED
  def process_info(thread_name_length = T.unsafe(nil)); end

  # Lazy initializes the context hash and assigns a key value pair.
  def set_context(key, value); end

  # Returns the value of attribute tags.
  def tags; end

  # Sets the attribute tags
  def tags=(_arg0); end

  # Returns the value of attribute thread_name.
  def thread_name; end

  # Sets the attribute thread_name
  def thread_name=(_arg0); end

  # Returns the value of attribute time.
  def time; end

  # Sets the attribute time
  def time=(_arg0); end

  def to_h(host = T.unsafe(nil), application = T.unsafe(nil), environment = T.unsafe(nil)); end
end

SemanticLogger::Log::CALLER_REGEXP = T.let(T.unsafe(nil), Regexp)
SemanticLogger::Log::MAX_EXCEPTIONS_TO_UNWRAP = T.let(T.unsafe(nil), Integer)

# Keys passed in without a payload that will be extracted and the remainder passed into the payload.
SemanticLogger::Log::NON_PAYLOAD_KEYS = T.let(T.unsafe(nil), Array)

module SemanticLogger::Loggable
  mixes_in_class_methods ::SemanticLogger::Loggable::ClassMethods

  class << self
    def included(base); end
  end
end

module SemanticLogger::Loggable::ClassMethods
  # Measure and log the performance of an instance method.
  #
  # Parameters:
  # method_name: [Symbol]
  # The name of the method that should be measured.
  #
  # options: [Hash]
  # Any valid options that can be passed to measure.
  #
  # Approximate overhead when logging a method call with a metric:
  # 0.044 ms  per method call.
  # 0.009 ms  per method call. If `min_duration` is not met
  # 0.0005 ms per method call. If `level` is not met
  def logger_measure_method(method_name, min_duration: T.unsafe(nil), metric: T.unsafe(nil), log_exception: T.unsafe(nil), on_exception_level: T.unsafe(nil), message: T.unsafe(nil), level: T.unsafe(nil)); end

  private

  # Dynamic Module to intercept method calls for measuring purposes.
  def logger_measure_module; end
end

# Logger stores the class name to be used for all log messages so that every
# log message written by this instance will include the class name
class SemanticLogger::Logger < ::SemanticLogger::Base
  include ::SemanticLogger::Concerns::Compatibility

  # Returns a Logger instance
  #
  # Return the logger for a specific class, supports class specific log levels
  # logger = SemanticLogger::Logger.new(self)
  # OR
  # logger = SemanticLogger::Logger.new('MyClass')
  #
  # Parameters:
  # klass
  # A class, module or a string with the application/class name
  # to be used in the logger
  #
  # level
  # The initial log level to start with for this logger instance
  # Default: SemanticLogger.default_level
  #
  # filter [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied
  # regular expression. All other messages will be ignored
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false
  def initialize(klass, level = T.unsafe(nil), filter = T.unsafe(nil)); end

  def <<(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def datetime_format; end
  def datetime_format=(_arg0); end
  def formatter; end
  def formatter=(_arg0); end

  # Place log request on the queue for the Appender thread to write to each
  # appender in the order that they were registered
  #
  # Subscribers are called inline before handing off to the queue so that
  # they can capture additional context information as needed.
  def log(log, message = T.unsafe(nil), progname = T.unsafe(nil), &block); end

  def progname; end
  def progname=(_arg0); end
  def sev_threshold; end
  def sev_threshold=(level); end
  def silence_logger(new_level = T.unsafe(nil), &block); end
  def unknown(message = T.unsafe(nil), payload = T.unsafe(nil), exception = T.unsafe(nil), &block); end
  def unknown?; end

  class << self
    def call_subscribers(log); end
    def processor; end
    def subscribe(object = T.unsafe(nil), &block); end

    # Returns the value of attribute subscribers.
    def subscribers; end

    # Switch to the synchronous processor
    def sync!; end

    # Running without the background logging thread?
    def sync?; end
  end
end

module SemanticLogger::Metric; end

class SemanticLogger::Metric::Signalfx < ::SemanticLogger::Appender::Http
  # Create SignalFx metrics appender.
  #
  # Parameters:
  # token: [String]
  # Access Token to use for sending metrics.
  # Obtain the Signalfx token via the Signalfx Web UI under `Organization` -> `Access Tokens`.
  #
  # dimensions: [Array<String>]
  # Dimensions to forward to signalfx when they are present in the named tags of any log message.
  # By default `application` and `host` are always included as dimensions in all forwarded metrics.
  # Example: [:user_id, :state]
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true.
  # The Proc must return true or false.
  #
  # host: [String]
  # Name of this host to send as a dimension.
  # Default: SemanticLogger.host
  #
  # application: [String]
  # Name of this application to send as a dimension.
  # Default: SemanticLogger.application
  #
  # url: [String]
  # Override the SignalFx service url.
  # For historical data use: https://backfill.signalfx.com/v1/backfill
  # Default: https://ingest.signalfx.com
  #
  # Notes:
  #
  # When sending a metric to Signalfx, it is necessary to send both a `gauge` and a `counter` when a
  # duration is included in the metric, otherwise it is not possible to chart counts of the metric.
  # Unfortunately this doubles the number of metrics, but it is the way Signalfx works.
  # Using a `count` of a `gauge` in a chart will significantly under-count the number of occurrences.
  #
  # If dimensions are added to the metric, then the metric will be sent as-is and
  # the above logic will _not_ be applied.
  #
  # Example, Gauge metric, supplying the duration in `metric_amount`:
  # logger.info(metric: 'Filters.average', metric_amount: 1.2, dimensions: {user: 'jbloggs'})
  #
  # Example, Counter metric:
  # logger.info(metric: 'Filters.count', dimensions: {user: 'jbloggs'})
  #
  # Example, Counter metric with a count other than 1:
  # logger.info(metric: 'Filters.count', metric_amount: 23, dimensions: {user: 'jbloggs'})
  #
  # When a duration is supplied and no dimensions are supplied:
  # logger.info(metric: 'Common/User/authorize', duration: 1.4)
  #
  # Then it is translated into the following 2 log entries under the covers:
  # logger.info(metric: 'Application.average', metric_amount: 1.4, dimensions: {class: 'Common::User', action: 'authorize'})
  # logger.info(metric: 'Application.counter', metric_amount: 1, dimensions: {class: 'Common::User', action: 'authorize'})
  #
  # Similarly with a measure block which automatically supplies the duration:
  # logger.measure_info(metric: 'Common/User/authorize') do
  # sleep 1
  # end
  def initialize(token:, dimensions: T.unsafe(nil), url: T.unsafe(nil), formatter: T.unsafe(nil), **args, &block); end

  # Logs in batches
  def batch(logs); end

  # Returns the value of attribute full_url.
  def full_url; end

  def log(log); end

  # Only forward log entries that contain metrics.
  def should_log?(log); end
end

SemanticLogger::Metric::Signalfx::END_POINT = T.let(T.unsafe(nil), String)

# Thread that submits and processes log requests
class SemanticLogger::Processor < ::SemanticLogger::Appender::Async
  def initialize(max_queue_size: T.unsafe(nil)); end

  # Returns the value of attribute appenders.
  def appenders; end

  # Start the appender thread
  def start; end

  class << self
    # Internal logger for SemanticLogger
    # For example when an appender is not working etc..
    # By default logs to $stderr
    def logger; end

    # Sets the attribute logger
    def logger=(_arg0); end
  end
end

module SemanticLogger::Reporters; end

# When using Minitest to run tests, log start and end messages for every test to the log file.
# On completion the time it took to run the test is also logged.
#
# For example, add the following lines to `test_helper.rb`:
# require 'minitest/reporters'
#
# reporters = [
# Minitest::Reporters::ProgressReporter.new,
# SemanticLogger::Reporters::Minitest.new
# ]
# Minitest::Reporters.use!(reporters)
#
# And add `gem minitest-reporters` to the Gemfile.
#
# Log entries similar to the following should show up in the log file:
#
# 2019-02-06 18:58:17.522467 I [84730:70256441962000] Minitest -- START RocketJob::DirmonEntry::with valid entry::#archive_file test_0001_moves file to archive dir
# 2019-02-06 18:58:17.527492 I [84730:70256441962000] (4.980ms) Minitest -- PASS RocketJob::DirmonEntry::with valid entry::#archive_file test_0001_moves file to archive dir
# 2019-02-06 18:58:17.527835 I [84730:70256441962000] Minitest -- START RocketJob::DirmonEntry::#job_class::with a valid job_class_name test_0001_return job class
# 2019-02-06 18:58:17.529761 I [84730:70256441962000] (1.882ms) Minitest -- PASS RocketJob::DirmonEntry::#job_class::with a valid job_class_name test_0001_return job class
class SemanticLogger::Reporters::Minitest < ::Minitest::AbstractReporter
  include ::SemanticLogger::Loggable
  extend ::SemanticLogger::Loggable::ClassMethods

  def after_test(test); end
  def before_test(test); end

  # Returns the value of attribute io.
  def io; end

  # Sets the attribute io
  def io=(_arg0); end

  def logger; end
  def logger=(logger); end

  class << self
    def logger; end
    def logger=(logger); end
  end
end

class SemanticLogger::Subscriber < ::SemanticLogger::Base
  # Initializer for Abstract Class SemanticLogger::Subscriber
  #
  # Parameters
  # level: [:trace | :debug | :info | :warn | :error | :fatal]
  # Override the log level for this subscriber.
  #
  # formatter: [Object|Proc]
  # An instance of a class that implements #call, or a Proc to be used to format
  # the output from this subscriber
  # Default: Use the built-in formatter (See: #call)
  #
  # filter: [Regexp|Proc]
  # RegExp: Only include log messages where the class name matches the supplied.
  # regular expression. All other messages will be ignored.
  # Proc: Only include log messages where the supplied Proc returns true
  # The Proc must return true or false.
  #
  # application: [String]
  # Name of this application to appear in log messages.
  # Default: SemanticLogger.application
  #
  # host: [String]
  # Name of this host to appear in log messages.
  # Default: SemanticLogger.host
  #
  # metrics: [Boolean]
  # Whether to log metric only entries with this subscriber.
  # Default: false
  def initialize(level: T.unsafe(nil), formatter: T.unsafe(nil), filter: T.unsafe(nil), application: T.unsafe(nil), environment: T.unsafe(nil), host: T.unsafe(nil), metrics: T.unsafe(nil), &block); end

  # Allow application name to be set globally or on a per subscriber basis.
  def application; end

  # Sets the attribute application
  def application=(_arg0); end

  # A subscriber should implement close if it can.
  def close; end

  # Whether this appender is logging to stdout or stderror
  def console_output?; end

  # Returns [SemanticLogger::Formatters::Default] default formatter for this subscriber.
  def default_formatter; end

  # Allow environment name to be set globally or on a per subscriber basis.
  def environment; end

  # Sets the attribute environment
  def environment=(_arg0); end

  # A subscriber should implement flush if it can.
  def flush; end

  # Every appender has its own formatter
  def formatter; end

  # Set the formatter from Symbol|Hash|Block
  def formatter=(formatter); end

  # Allow host name to be set globally or on a per subscriber basis.
  def host; end

  # Sets the attribute host
  def host=(_arg0); end

  # Returns the current log level if set, otherwise it logs everything it receives.
  def level; end

  # Method called to log an event
  def log(log); end

  # Give each appender its own logger for logging.
  # For example trace messages sent to services or errors when something fails.
  def logger; end

  # Sets the attribute logger
  def logger=(_arg0); end

  # Sets the attribute metrics
  def metrics=(_arg0); end

  # Whether this log entry meets the criteria to be logged by this appender.
  def should_log?(log); end

  private

  # Return the level index for fast comparisons.
  # Returns the lowest level index if the level has not been explicitly
  # set for this instance.
  def level_index; end

  # Whether to log metric only entries with this subscriber
  def metrics?; end
end

# Thread that submits and processes log requests
class SemanticLogger::SyncProcessor
  extend ::Forwardable

  def initialize(appenders = T.unsafe(nil)); end

  def add(*args, &block); end

  # Returns the value of attribute appenders.
  def appenders; end

  def close(*args, &block); end
  def flush(*args, &block); end
  def log(*args, &block); end
  def reopen(*args, &block); end
  def start; end

  class << self
    # Internal logger for SemanticLogger
    # For example when an appender is not working etc..
    # By default logs to $stderr
    def logger; end

    # Sets the attribute logger
    def logger=(_arg0); end
  end
end

module SemanticLogger::Test; end

# Logging class to captures all logging events in memory.
#
# Example:
#
# class UserTest < ActiveSupport::TestCase
# describe User do
# let(:capture_logger) { SemanticLogger::Test::CaptureLogEvents.new }
# let(:user) { User.new }
#
# it "logs message" do
# user.stub(:logger, capture_logger) do
# user.enable!
# end
# assert_equal "Hello World", capture_logger.events.last.message
# assert_equal :info, capture_logger.events.last.level
# end
# end
# end
class SemanticLogger::Test::CaptureLogEvents < ::SemanticLogger::Subscriber
  # By default collect all log levels, and collect metric only log events.
  def initialize(level: T.unsafe(nil), metrics: T.unsafe(nil)); end

  # Returns the value of attribute events.
  def events; end

  # Sets the attribute events
  def events=(_arg0); end

  def log(log); end
end

# Internal-use only utility functions for Semantic Logger.
# Not intended for public use.
module SemanticLogger::Utils
  class << self
    # Borrow from Rails, when not running Rails
    def camelize(term); end

    def constantize_symbol(symbol, namespace = T.unsafe(nil)); end

    # Extract the backtrace stripping off the leading semantic logger entries.
    # Leaves all other system and gem path entries in place.
    def extract_backtrace(stack = T.unsafe(nil)); end

    # Whether this path should be excluded from any cleansed backtrace
    def extract_path?(path); end

    def extract_paths; end

    # Returns the visibility for an instance method
    def method_visibility(mod, method_name); end

    # Try to strip everything off of the supplied backtrace, until the first application stack entry is at the top.
    # For example all leading gem paths and built-in ruby code paths are removed from the top.
    # Once the first application entry is found, the remaining stack is returned.
    def strip_backtrace(stack = T.unsafe(nil)); end

    # Whether this path should be excluded from any cleansed backtrace
    def strip_path?(path); end

    # Paths to exclude in the stripped backtrace
    # Includes Gems and built-in Ruby code paths
    def strip_paths; end
  end
end

SemanticLogger::VERSION = T.let(T.unsafe(nil), String)
